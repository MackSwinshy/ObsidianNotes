---
Type: 
Difficulty: 
tags:
  - 知识点/选择必修三/成对数据的统计分析
creation time: 2025/06/11 09:30
last-modified time: 2025/07/24 10:28
---
对于线性相关关系较强的两个变量 $x$ 和 $Y$，我们可以用一次函数来刻画 $x$ 对 $Y$ 的影响，而把影响 $Y$ 的其他因素作为随机误差，得到：
$$Y=bx+a+e\,,e\sim N(0,\sigma^2)$$ 我们称该式为 $Y$ 关于 $x$ 的*一元线性回归模型*（simple linear regression model），其中 $Y$ 称为因变量或*响应变量*，$x$ 称为自变量或*解释变量*；$a,b$ 是模型的未知参数，$a$ 称为截距参数，$b$ 称为斜率参数；$e$ 是 $Y$ 与 $bx+a$ 之间的随机误差
- 理解：
	- $x$ 和 $Y$ **是相关关系而非函数关系**，$Y$ 不能由 $x$ 唯一确定，其是随机变量，在等式右边体现在 $e$ 也是随机变量
	- 响应变量 $Y$ 大写是因为随机变量通常大写，解释变量 $x$ 小写是因为在回归分析中，常常给定了固定值，故用小写 $x$ 表示其取值
	- $E(e)=0,D(e)=\sigma^2\quad\implies$  对于给定的自变量 $x_i$，此时因变量 $Y$ 总体的均值为 $bx_i+a$，即其**均值**与自变量成线性函数关系

一般地，设变量 $x$ 与 $Y$ 线性相关，则称 $\hat y=\hat bx+\hat a$ 为 $Y$ 关于 $x$ 的*经验回归方程*，其图形称为经验回归直线，这种求出方程的方法叫最小二乘法，得到的 $\hat a,\hat b$ 叫做 $a,b$ 的*最小二乘估计*（least squares estimate），其中
$$\hat b=\frac{\sum_{i=1}^n (x_i-\bar x)(y_i-\bar y)}{\sum_{i=1}^n (x_i-\bar x)^2}$$
$$\hat a=\bar y-\hat bx$$
- 理解：$\hat \cdot$ 表示是**预测/估计**值，是从样本数据计算出的近似值；既然是预测就会和实际值存在误差，将观测值减去预测值称为*残差*   $\hat e$
	- 注意随机误差 $e$ 和残差 $\hat e$ 的区别， $e=y-bx-a, \hat e=y-\hat bx-\hat a$ 

|    符号    |     含义     |  $\hat\cdot$ 意义  |
| :------: | :--------: | :--------------: |
|   $y$    | 真实的**观测值** |      实际数据点       |
| $\hat y$ |  回归模型的预测值  |    对 $y$ 的估计     |
|   $x$    |  给定的自变量取值  |      实际数据点       |
|   $b$    |   真实的参数    |    理论值（可能未知）     |
| $\hat b$ | 参数的**估计值** |    通过样本计算的近似值    |
|   $e$    |  真实的随机误差   | $y$ 关于 $x$ 的随机部分 |
| $\hat e$ |     残差     |    实际值和预测值的偏差    |
- 推导思路：要找一条适当的直线 $y=bx+a$，使样本数据的散点整体上与这条直线最接近 $\implies$ 用样本数据点与直线的竖直距离 $y_i-bx_i-a$ （方便计算）来衡量"整体接近程度"$\implies$ 整体程度说明每个样本点都要考虑，因此记 $Q=\sum_{i=1}^n (y_i-bx_i-a)^2$ 来表示      $\implies$ 数据点越接近直线等价于 $Q$ 越小，$x_i,y_i$ 是已知数据，所以 $Q$ 是 $a,b$ 的函数，可以求出使 $Q$ 达到最小的 $a,b$ （通过最小二乘法就得到这样的 $\hat a,\hat b$）
$$Q(a,b)=\sum_{i=1}^n (y_i-bx_i-a)^2\\=\sum_{i=1}^n [y_i-bx_i-(\bar y-b\bar x)+(\bar y-b\bar x)-a]^2\\=\sum_{i=1}^n [(y_i-\bar y)-b(x_i-\bar x)+(\bar y-b\bar x)-a]^2\\=\sum_{i=1}^n [(y_i-\bar y)-b(x_i-\bar x)]^2+2\sum_{i=1}^n [(y_i-\bar y)-b(x_i-\bar x)]\times[(\bar y-b\bar x)-a]+n[(\bar y-b\bar x)-a]^2$$
$$Q(a,b)=\sum_{i=1}^n [(y_i-\bar y)-b(x_i-\bar x)]^2+n(\bar y-b\bar x-a)^2$$
$$Q(a,b)_{min}=\sum_{i=1}^n [(y_i-\bar y)-b(x_i-\bar x)]^2\\=b^2\sum_{i=1}^n (x_i-\bar x)^2-2b\sum_{i=1}^n (x_i-\bar x)(y_i-\bar y)+\sum_{i=1}^n (y_i-\bar y)^2$$ 是关于 $b$ 的二次函数

******
决定系数 $R^2$：用于比较模型的拟合效果，$R^2$ 越大代表残差平方和越小，即模型的拟合效果越好
$$R^2=1-\frac{\sum_{i=1}^n (y_i-\hat y_i)^2}{\sum_{i=1}^n (y_i-\bar y)^2}$$