---
创建时间: 2025/06/18 23:08
上次编辑时间: 2025/09/04 09:23
---

- 23:08 
	#编程/算法 
	# 第 2 章 -- 复杂度分析
	## 2.1 算法效率评估
	- 时间效率：算法运行时间的长短
	- 空间效率：算法占用内存空间的大小
	- 评估方法
		1. 实际测试：难以排除测试环境的干扰因素（单核 CPU之于并行算法）、展开完整测试非常耗费资源（严谨结论需要不同规模的数据量）
		2. 理论估算：渐进复杂度分析 asymptotic complexity analysis，**描述了随着输入数据大小的增加，算法执行所需时间和空间的增长趋势**（体现算法运行所需的时间和空间资源与输入数据大小之间的关系）
			- 时间/空间资源： 对应时间/空间复杂度 time/space complexity
			- 复杂度分析关注的==**不是**运行时间或占用空间的**具体值**，而是时间/空间**增长的趋势**==
	## 2.2 迭代与递归
	- 都是实现重复执行任务的手段
	1. 迭代 iteration：（在满足一定条件下）重复执行某段代码，直到条件不再满足，自下而上
		1. `for` 循环：预先知道迭代次数
		2. `while` 循环：自由度更高
	2. 递归 recursion：通过函数调用自身来解决问题，自上而下
		1. 递：程序不断深入地调用自身，通常传入给自身更小或更简化的参数，直到达到“终止条件”
		2. 归：触发“终止条件”后，程序从最深层的递归函数（函数本身）开始逐层返回，汇聚每一层的结果
		- 递归代码的三要素：
			- 终止条件：决定何时由递转归
			- 递归调用：递，函数调用自身，通常输入更小或更简化的参数
			- 返回结果：归，将当前递归层级的结果返回至上一层
		- 调用栈：递归函数每次调用自身时，系统都会为新开启的函数分配内存（上下文数据：局部变量、调用地址和其他信息等）
			- 函数的上下文数据都存储在称为“栈帧空间”的内存区域中，直至函数返回后才会被释放。因此，**递归通常比迭代更加耗费内存空间**
		- 尾递归 tail recursion：**如果函数在返回前的最后一步才进行递归调用**，则该函数可以被编译器或解释器优化，使其在空间效率上与迭代相当
			- 普通递归：当函数返回上一级的函数后还需继续执行代码，系统需要保留上一层调用的上下文
			- 尾递归的递归调用是函数返回前的最后一个操作，函数返回上一层级后无需执行其他操作，系统无需保留上一层函数的上下文
	- 递归求和的代码比较
		```python
		# 普通递归
		def recur(n):
			if n == 1:
				return 1
			res = recur(n-1)   # recur(3)=3+recur(2)=3+(2+recur(1))=3+(2+1)
			return n + res     # 求和操作是在"归"的过程中执行，每层返回都要执行一次求和操作 
		# 尾递归
		def tail_recur(n,res):
			if n == 0:
				return res 
			return tail_recur(n - 1, res + n)  # recur(3,0)=recur(2,3)=recur(1,5)=recur(0,6)=6
											   # 求和操作在"递"的过程中执行，"归"时只需层层返回即可 
		```
		- 递归树
	## 2.3 时间复杂度
	- 时间复杂度分析统计的不是算法运行时间（与运行平台、硬件条件等相关，不好统一），而是**算法运行时间随着数据量变大时的增长趋势**
		- 时间复杂度能够有效评估算法效率
		- 时间复杂度的推算方法更简便：只用计算操作数量统计，而不是计算操作运行时间统计
		- 时间复杂度也存在一定局限性（毕竟不是直接统计运行时间，根据实际数据大小有误差）
	- 函数的渐进上界（asymptotic upper bound）用*大 O记号*（big-*O* notation）表示。时间复杂度分析本质上是计算操作数量 $T(n)$ 的渐进上界
		- 数学定义：若存在正实数 $c$ 和实数 $n_0$ ，使得对于所有的 $n>n_0$ ，均有 $T(n) \le c \cdot f(n)$ ，则可认为 $f(n)$ 给出了 $T(n)$ 的一个渐进上界，记为 $T(n)=O(f(n))$
	- 具体推算方法
		1. step 1：统计操作数量 $T(n)$ （以下是简化技巧，因为渐进上界中的 $c$ 可以取任意大小 ）
			- 忽略 $T(n)$ 中的常数项
			- 忽略所有系数：例如循环 $2n$ 、 $5n+1$ 次等都可记为 $n$ 次
			- 循环嵌套时使用乘法
		2. step 2：判断渐进上界 
			- 时间复杂度由 $T(n)$ 中最高阶的项来决定
	- 常见类型： $O(1)<O(log\,n)<O(n)<O(n\,log\,n)<O(n^2)<O(2^n)<O(n!)$  
		- $O(log\,n)$ 反映了“每轮缩减到一半”的情况，常出现于基于分治策略的算法中，体现了“一分为多”和“化繁为简”的算法思想
		- $O(n\,log\,n)$ 常出现于嵌套循环中，两层循环的时间复杂度分别为 $O(n)$ 和 $O(log\,n)$ ，是主流排序算法如快速排序、归并排序、堆排序的时间复杂度
		- ==对于递归的时间复杂度分析==：把每次递归调用理解为 1 个节点，操作次数的统计就是计算**递归树上的所有节点的总操作次数**，如果每个节点的操作次数是常数量，则相当于计算总节点数量；若每个节点操作次数与 n 相关，则相当于数列求和
	- 代码示例
	```python 
	# O(n)，输入数据大小n要根据输入数据的类型赖具体确定
	def array_traversal(nums: list[int]) -> int:
		count = 0   # 遍历数组
		for num in nunms:  # 循环次数与数组长度成正比
			count += 1
		return count
	# O(n^2)
	def bubble_sort(nums: list[int]) -> int:  # 冒泡排序
	    count = 0
	    for i in range(len(nums)-1, 0, -1):   # 外循环执行n-1次
	        for j in range(i):    # 内循环依次执行n-1,n-2,...,2,1次，平均执行n/2次
	            if nums[j] > nums[j+1]:
	                tmp: int = nums[j]
	                nums[j] = nums[j+1]
	                nums[j+1] = tmp
	                count += 3
	    return count
	# O(2^n)
	def exp_recur(n: int) -> int:  # 递归求2的n次幂
	    if n == 1:
	        return 1
	    return exp_recur(n-1) + exp_recur(n-2)+1
	# O(logn)
	def logarithmic(n):   # 常见于每轮缩减到一半的情况，与指数阶恰恰相反
	    count = 0
	    while n > 1:
	        n = n / 2
	        count += 1
	    return count
	# O(nlogn)
	def linear_log_recur(n: int) -> int:
	    if n <= 1:
	        return 1
	    # 一分为二，子问题的规模减小一半
	    count = linear_log_recur(n // 2) + linear_log_recur(n // 2)
	    # 当前子问题包含 n 个操作
	    for _ in range(n):
	        count += 1
	    return count
	# O(n!)
	def factorial_recur(n: int) -> int:
	    if n == 0:
	        return 1
	    count = 0
	    # 从 1 个分裂出 n 个
	    for _ in range(n):
	        count += factorial_recur(n - 1)
	    return count
	```
	- 最差、最佳、平均时间复杂度
		- **算法的时间效率往往不是固定的，而是可能与输入数据的分布有关**
		- “最差时间复杂度”对应函数渐近上界，使用大 𝑂 记号表示。相应地，“最佳时间复杂度”对应函数渐近下界，用 $\Omega$ 记号表示
		- **最差时间复杂度更为实用，因为它给出了一个效率安全值**（但都是只出现于特殊的数据分布情况下），**平均时间复杂度可以体现算法在随机输入数据下的运行效率**，记为 $\Theta$